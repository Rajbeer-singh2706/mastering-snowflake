{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Hands on: Create Query Context\n",
    "'''\n",
    " show databases;\n",
    "use schema snowflake_sample_data.tpcds_sf10tcl;\n",
    "\n",
    "select count(*) from cataog_sales;\n",
    "select count(*) from customer;\n",
    "\n",
    "\n",
    "use schema snowflake_sample_data.tpch_sf1000;\n",
    "select count(*) from nation;\n",
    "select count(*) from snowflake_sample_data.tpch_sf1000.nation;\n",
    "\n",
    "create database employees;\n",
    "create table ttt(v variant);\n",
    "create database if not exists employees;\n",
    "\n",
    "\n",
    "show databases;\n",
    "describe database employees;\n",
    "drop databse employees;\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncreate database employees;\\ncreate stage mystage \\n# upload the file manully , => Data => Database => Stage => mystage =>from local upload the file\\nlist @mystage;\\n\\n\\n### \\nselect metadata$file_row_number, $1,$2 FROM @mystage/emp.csv;\\nselect infer_schema(\\n  location => '@mystage'\\n);\\n\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#16. Hands ON: INfer schema from staged CSV Files \n",
    "'''\n",
    "create database employees;\n",
    "create stage mystage \n",
    "# upload the file manully , => Data => Database => Stage => mystage =>from local upload the file\n",
    "list @mystage;\n",
    "\n",
    "\n",
    "### \n",
    "select metadata$file_row_number, $1,$2 FROM @mystage/emp.csv;\n",
    "select infer_schema(\n",
    "  location => '@mystage'\n",
    ");\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Stages \n",
    " # Internal stage\n",
    " # Extranl Stage [ BLob storage -> S3/AZURE]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Role \\n2. Warehouse\\n3. Databse \\n4. Schema \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query Context \n",
    "'''\n",
    "1. Role \n",
    "2. Warehouse\n",
    "3. Databse \n",
    "4. Schema \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal vs external Stage \n",
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n * File Format: CSV,JSON,Parquet\\n * Upload JSON Data into VARIANT\\n * JSON Objects and arrays\\n * Flatten Arays and Lateral Joins\\n * Primary and Foreign Constraints\\n * Temporary and Transient Tables\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Section 4: Loading And Processing JSON Data \n",
    "'''\n",
    " * File Format: CSV,JSON,Parquet\n",
    " * Upload JSON Data into VARIANT\n",
    " * JSON Objects and arrays\n",
    " * Flatten Arays and Lateral Joins\n",
    " * Primary and Foreign Constraints\n",
    " * Temporary and Transient Tables\n",
    " * Materialized Views\n",
    "'''\n",
    "## 20. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n - CSV( Comma-Seperated Values )  => Tabular row-oriented(good for transactions)\\n - JSON( JavaScript Object Notation) => For hierarchical Semi-Strucutred data\\n - XML( Extensible Markup Language)=> For hierarchical Semi-Strucutred data\\n - PARQUET                          => tabular format, but binary compressed and column-oriented( Good for anlaytics)\\n - ORC(OPimized Row Columnar) => ony for loading, tabular format, but coumn-oriented(good for anlytics)\\n - AVRO => only for loading, Row-oritned(good for ransaction), compressino binary format, Additinal Schema evolutin metdata(in JSON),\\n FOR RPC Serilization , \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 21. Review: File Formats\n",
    "'''\n",
    " - CSV( Comma-Seperated Values )  => Tabular row-oriented(good for transactions)\n",
    " - JSON( JavaScript Object Notation) => For hierarchical Semi-Strucutred data\n",
    " - XML( Extensible Markup Language)=> For hierarchical Semi-Strucutred data\n",
    " - PARQUET                          => tabular format, but binary compressed and column-oriented( Good for anlaytics)\n",
    " - ORC(OPimized Row Columnar) => ony for loading, tabular format, but coumn-oriented(good for anlytics)\n",
    " - AVRO => only for loading, Row-oritned(good for ransaction), compressino binary format, Additinal Schema evolutin metdata(in JSON),\n",
    " FOR RPC Serilization , \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22. Hands ON: Upload JSON Data \n",
    "# 23. Hands ON: Transform Your Data\n",
    "# 24. Review: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25. Hands ON; Flatten JSON Data.\n",
    "# 26. Review: JSON Data Flattening\n",
    "'''\n",
    " - FLATTEN()\n",
    " - LATERAL  :  Keyword not function, lateral is like JOIN keyword, extension of SQL Join \n",
    " - TABLE()\n",
    " - RESULT_SCAN()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27. HandsON: Add Constraints and Materialized Views\n",
    "# 28. Review: Temporary Tables and Materialized views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q) What is View ?\n",
    "# Q) What is materalized View?\n",
    "# Q) Difference b/w View vs Materialized View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  * Snowflake Turorial \\n  * Snowflake  Sample Databases\\n  * Snowflake Data Extraction\\n  * Synthetic Data Generation\\n  * Extenal  Data Extraction\\n  * Snowflake \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 5: Sample Data Extraction and Generation\n",
    "'''\n",
    "  * Snowflake Turorial \n",
    "  * Snowflake  Sample Databases\n",
    "  * Snowflake Data Extraction\n",
    "  * Synthetic Data Generation\n",
    "  * Extenal  Data Extraction\n",
    "  * Snowflake \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 HANDS ON : Extract Data Samples with Snowflake\n",
    "# 31 HANDS ON : Generate Synthetic Data with Snowflake\n",
    "# 32 HANDS ON : Generate Synthetic Data with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33. Review: Data Samle Extraction and Generation\n",
    "# 34. Review: Sequences and Identity Columns\n",
    "'''\n",
    " * Sequences\n",
    " * Identity Columns\n",
    " * UUIDs\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
